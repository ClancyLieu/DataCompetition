# 2022招商银行“Fintech精英训练营”数据竞赛
# 回顾总结

## 一、前言
2022年4月中上旬，我开始自学机器学习原理和技术；2022年4月29日，仅掌握SVM和ANN模型原理的我开启了自己的数据竞赛处子秀；2022年5月13日，人生中第一场数据竞赛收官。因官方没有公开，猜测竞赛报名人数1900左右，实际参赛人数近1000人，最终排名370左右。排名腰部，但对于初次参赛只会两种基础模型的我而言尚可接受。

本次招行数据竞赛令人印象深刻的点在于：B榜测试数据分布与训练集和A榜测试数据分布有差异。多亏了这一点，我才能从A榜排名垫底上升到综合排名腰部。通过参加本次竞赛，我对于特征工程、SVM和ANN模型的性能优化、分布变化下模型泛化能力的提高等都有了更深的理解。

## 二、赛题描述
公司存款是商业银行以信用方式吸收的企事业单位的存款，与零售存款相比，公司存款具备数额大、成本低、流动性强等特点。通过对公司存款流失的预测，银行一方面可以对公司客户的流失原因进行归因，不断提升服务水平；另一方面可以提前规划资产负债结构，保证充裕的流动性。因此，使用金融科技手段对公司存款流失进行预测具有重要的业务指导意义。

本次比赛为参赛选手提供了两个数据集，即训练数据集（train）和测试数据集（test_A榜/ test_B榜）。参赛选手需要基于训练数据集，通过有效的特征提取，使用分类算法构建公司客户存款流失预测模型，并将模型应用在测试数据集上，输出对测试数据集中公司客户存款流失概率的预测。

## 三、竞赛记录
对本次竞赛过程中，模型性能有大幅变化的节点，可以与总体思路中的经验、感想相互印证。

**日期	操作	模型性能变化AUC**

2022/4/29	数据分析与预处理	SVM0.5

2022/5/1	特征数据标准化，删除共线特征	SVM0.88，线上0.85

2022/5/2	选择特征分离度最高的4个特征	SVM0.88

2022/5/4	基于提高分离度的原则手动构造特征，存款特征除以存款增量特征等	SVM0.925

2022/5/5-
2022/5/7	参加产品赛道	-

2022/5/8	使用三层神经网络+4个高分离度特征	ANN0.87

2022/5/8	使用4个高分离度+11个中等分离度特征，ANN骤降	ANN0.72

2022/5/9	暴力进行特征相乘，构造高分离度的新特征	SVM0.95，线上0.92

2022/5/10	A榜关闭，B榜发布B榜数据预处理，按A榜筛选后的特征输入模型	SVM0.92，线上0.73

2022/5/11	train集特征按均值差往test集偏移，并使用4个高分离度的原特征	SVM0.88，线上0.7382

2022/5/12	对抗验证思路，选择5000训练样本，使用特征构造后得到的高分离度特征	SVM0.88，线上0.7489

## 四、总体思路
通过本次招商银行竞赛，我进行了一系列的数据检查与预处理、数据探索性分析、手动&自动的特征工程、模型选择与调参、线上验证与精细化调整等历程。总结本次参与竞赛的思路如下：
### 1.数据预处理
通过excel表等浏览数据各特征字段是否存在不规范的值（如空值的nan、none、？、-等多种表达方式）。

计算空值比例，并依据特征含义确定每个特征如何对空值进行填充：如果为业务类连续特征，如每天发生的业务量，如果为空可填充为0；如果为业务类分类特征，可视情况将空值单独分为一类，或者归为分类中的基础类别（如是/否中的否）。如果是个体的某种属性，比如身高体重，我们认为其服从正态分布，那空值可以采用平均值填充。如果各特征空值集中于少数样本，可以考虑将该部分样本剔除；如果特定特征空值比率过高，也可以考虑直接剔除该特征。

招商银行竞赛提供的数据集基本没有做任何数据说明，参赛人员只能依据字段名称中的英文缩写判断该字段的类型（计数/金额/时间字段、平均/总量字段），综合判断分析之下，我对招行公司存款流失数据集预处理方式如下：

（1）数据集中存在？和空白两种空值，问号转换为nan空值；

（2）大量字段猜测为业务类金额/计数字段，结合之前信息系统项目管理经验，空值应该代表该用户未发生此类业务，等同于0.所以大部分连续变量字段空值填充为0。

（3）有较多字段都奇特的以2结尾，尤其是最小值都是2.结合有三个字段分别为转入金额、转出金额和净转入金额，其中净转入金额=转入金额-转出金额+2.所以猜测2应该是数据脱密导致的（也可能是为了方便进行对数变换？）所以这一部分字段有值的记录会首先进行减2，再填充空值为0.

（4）分类字段中基本是将空值额外作为一种分类特征，单独增加编码。

### 2.数据探索性分析
在经过数据预处理后，得到无空值的样本特征数据。进行数据探索性分析的目的是查看各特征数据的分布、不同标签分类下特征数据分布的差异。

#### (1)查看各特征分布

通过概率密度图、频率直方图等查看。查看特征分布的目的主要是检查该数据是否近似服从正态分布、是否存在离群点。对于大部分经济变量，尤其是计数/金额类，一般近似服从对数正态分布，右偏长尾数据会在后续模型训练时影响模型精度。检查离群点和各种奇异数据，可以便于从数据分布上发现可能存在的数据错误，例如增长率、利润率等比率数据一般而言不会出现几万这一级别的值，如果出现了可能代表数据存在质量问题。

#### (2)查看标签与特征联合分布

通过分标签的概率密度/频率直方图，或者（服从正态分布下）查看不同标签下均值、方差差异。查看标签与特征的联合分布，只查看不同分类或不同分类概率下特征取值的分布概率密度。通过检查这一项可以查看特征在不同标签上的分离度，同时也可以对比不同测试集上特征与标签联合分布的差异，判断测试集分布与训练集分布相比是否出现显著变化。

这一部分，我在招行比赛中仅仅是检查了特征本身的分布，即判断哪些特征为近似对数正态分布，需要进行对数处理。但对于特征与分类联合分布并没有进行详细分析（在特征评分的部分有用到这一思想），因此后续测试集分布变化后，对于怎么调整特征没有形成清晰的思路。
### 3.特征工程
特征工程部分，我将其分为特征变换、特征构造和特征评价三部分。
#### (1)特征变换
特征变换是指，依据数据探索性分析的结果，对特征数据进行数学变换。主要包括连续变量的对数化和标准化、分类变量的数值化。

对数化，即对特征数据进行对数变换。主要用于特征近似服从于对数正态分布时，通过对数变换将特征转换为正态分布变量。（至于为什么一定要转换为正态分布，目前于我而言原因有二：一是对数正态分布的特征会存在右偏长尾，较小比例的高特征取值会影响模型的性能，而通过对数处理后得到正态分布变量一方面会压缩高值的量级，另一方面经过标准化处理后可以对称的将特征取值缩放至较小范围。二是受传统统计回归影响较大，比较注重变量是否符合正态分布。）

标准化，即将正态分布特征变换为标准正态分布特征。标准化的主要目的还是压缩取值的量级，将不同量纲的特征统一变换为无量纲特征。标准化后的特征输入到模型中，能够减小因量级较高的特征取值导致的模型性能问题。比如在人工神经网络模型中，如果使用sigmoid作为激活函数，特征变量取值较大的话，在第一层神经元反向传播时会出现梯度消失现象，导致模型达到部分的最优化，模型分类效果极差且随权重矩阵初始化值的变化而剧烈变化。

数值化，即将分类变量变换为数值以供模型分析。一般来说分类变量的数值化有三种方法：独热编码，平均数/中位数/频数编码，普通数值编码。对于不同分类间无先后次序时，可将分类变量进行独热编码（类似哑变量）；有先后次序时，可进行普通数值编码，如0-5。如果分类变量取值频数呈金字塔分布，且与样本类别之间存在单调关系，也可以使用频数编码，以该类别出现的频数作为该类的取值。举个显而易见的例子，比如我们将收入级别由高到低分为A、B、C共3个级别，我们想预测其为高消费还是低消费两个类别。很明显收入级别与消费量有单调关系，如果收入级别分布为金字塔形，那我们就可以使用频数编码，这样编码后频数与消费量依旧是单调关系，从而可以保障编码后特征的信息量。如果分类取值在某个变量的平均数或众数上是单调的，那我们就可以采用均值/众数编码。还是同一个例子，如果收入级别频数分布不是金字塔而是纺锤形，那此时使用频数编码会损失信息，但如果找到某个中间变量在不同收入级别上为单调变化的，就可以使用这个中间变量的平均数进行编码。我在招行比赛中使用了频数编码，与独热编码相比模型性能无明显差异。
#### 2)特征评价
当我们完成特征变换后的数据集后，我们实际上已经具备了能够输入模型的特征集合。但并非所有特征都需要被输入模型，一来并非所有特征都有助于模型划分样本类别，有些特征加入反而会降低模型性能；二来即便特征加入有助于提高模型在验证集上的表现，加入过多细枝末节的特征很有可能使模型过拟合。因此特征的选择实际上也可以划分为两个阶段：

首先，如何判断特征的加入是否有助于提高模型在训练集的表现（减小经验误差）。最简单直接的特征选择方法，将单个特征输入模型，以AUC分值大小或提升的幅度决胜负，但很明显当样本量比较大、特征数量比较多时，这种方法对时间和算力的要求都比较高；当特征已经经过一轮筛选，需要进一步精细筛选提高模型表现时方可采用。这一阶段我对于特征选择的核心原则是：选择分离度较高的特征。分离度是指，特征分布在不同分类上有足够明显的差异，当特征近似服从于正态分布时，分布的差异就体现在均值和标准差上。这一核心原则实际上受到了SVM模型思想的影响。SVM模型的理论前提是不同分类的样本在某个高维特征空间是线性可分的，因此我们可以将特征向量映射为高维向量，实现样本类别的划分。而具体到某一个特征上，线性可分本身意味着样本在该特征上存在较高的分离度。因此我将高分离度的特征挑选出来，这个特征大概率是可以提高模型表现的（尤其是SVM模型）。因此基于这个高分离度的核心原则，我构建了一个简单好用的特征评分指标：在训练集上该样本分类为1的特征取值平均值mean1与分类为0的特征取值平均值mean2之差，除以训练集上该特征的标准差std，即abs(mean1-mean2)/std。因为该评分指标只应用于标准化之后的特征，特征近似服从于标准正态分布，因此特征整体均值为0，标准差为1.倘若不同分类下均值差接近1，即1个标准差，那这个差异实际上已经是非常明显了。具体的评价阈值可以依据需求来确定，我在招商银行比赛中使用的是0.5-0.8为中等分离度特征，0.8-1为高分离度特征，而1以上为超高分离度特征。经过评价，原数据集中最有效的4个特征评分均在0.5-1之间。经过招商比赛的验证，这个方法简单好用，适用于前期特征的快速筛选。如果这个方法失效，一般是特征的预处理和数学变换没做到位。

其次是如何判断高评分特征的加入是否会导致过拟合，即如何在高评分特征中做选择。最简单粗暴的方法还是进行遍历特征集合，用线下AUC分值增加量做评判。这一部分的方法本质上是解决过拟合。过拟合意味着测试集和训练集的分布存在差异，而我们特征选择过度迎合了训练集的分布。一个简单直接的思路：我们从训练集中找到特征分布与测试集类似的样本集合，然后基于这个训练集子集进行特征的构造和评分，那么筛选出的特征在测试集上大概率也是适用的。这个思路实际上就是对抗验证的思路。
#### 3)特征构造
如果仅依赖原数据集中已有的特征，一般而言模型效果无法达到上限。例如采用SVM或ANN等不会自动构造特征的模型，输入原数据集中特征评分最高的4个特征，训练后验证集上AUC仅为0.88。经过人为的特征构造，可以进一步提高得分。

具体特征构造的方法，一方面可以基于对业务的理解构造新特征，另一方面通过数学方法进行暴力特征构造和筛选。因为招商银行比赛并未提供特征的说明，所有特征的含义都基于猜测，实际上较难通过业务理解和理论基础构造新特征。我在招商银行比赛中是通过数学变换的方法进行的暴力破解。

暴力特征构造的总体思路：在原本的高分离度特征基础上，进一步强化特征的分离度（但是不能大幅改变特征取值的量级）。这一特征构造思路可以有效提升SVM模型的表现。我在本次比赛中使用的比较有效的暴力特征构造的方法有两种：特征降幂和特征相乘。因为特征经过标准化后，大量特征位于0-1之间，因此通过取立方根等可以提高特征的分离度。而高分离度特征相乘，也可以构造出高分离度的新特征，当然大部分无法解释。经过简单的求方根和4重特征相乘的暴力特征构造后，筛选出高评分的特征输入SVM模型，线下AUC可以达到0.93左右。如果进一步开展复杂的特征构造，理论上线下AUC还能进一步提升。我因为在A榜阶段过拟合的现象就开始愈发严重，就没有进一步进行特征构造。
### 4.数据模型与参数设置
因为我是参赛前刚学会SVM和ANN模型，招商的比赛也只使用了这两个模型，其中ANN模型参数初始化上的一些小trick是在B榜开榜后才恍然大悟，因此实际上主要使用的是SVM模型。

总结一下竞赛过程中使用SVM的评分变化历程，我认为SVM模型性能的提升有以下几个关键点：

+ SVM模型对样本特征是否进行了标准化有一定要求，但要求不高。如果各个特征的量级都在同一个层面上，不进行严格的标准化也不影响模型性能，比如一个特征进行了标准化，另一个特征经过数学变换后量级由个位数变为十位数百位数，模型性能不会骤降。
+ SVM模型性能的提高关键是输入增量信息。即加入模型的特征应该提供增量信息，才能够提高样本的高维线性可分程度。简单起见，提供增量信息比较难以衡量，但其必要条件是新输入的特征必定是高分离度的特征。因此前期SVM模型性能的提升可以靠特征评分+高评分特征输入模型实现，后期特征足够多后就需要逐特征精细化的评估。例如在B榜期间，我发现同样是高分离度的特征，其中一个特征加入模型反而会降低模型AUC。总之高分离度特征是增量信息的必要条件，但不是充分条件。
+ SVM模型调参对模型评分的提升微乎其微，更换内核类型/gamma参数基本无影响。结合其他参赛者的经历，各大模型完成基础的参数设置后，继续调参或更换随机种子的边际效益都非常低（当然竞赛中该用种子大法他们还是会用的:D）
+ 在特征较少、样本量也较小的情况下，SVM模型的训练效果非常不稳定，样本量提高后即使特征数量少也可以实现稳定的模型性能。与之对比明显的是ANN模型即使样本量少性能也非常稳定（嗯，稳定在中等性能，死活提升不上去）


而人工神经网络模型ANN在参数初始化上存在一些小trick，在A榜阶段没注意到一直疑惑为什么ANN性能这么差，输入的特征越多性能越差。直到如今，我只是知道怎么设置能够使ANN能达到平均性能水平，没有找到ANN性能提升的要点。

+ ANN模型对特征标准化/归一化的要求非常高。如果使用sigmoid函数作为激活函数的化，不对高量级的特征进行标准化会导致模型出现梯度消失现象，最终模型性能低下。比较典型的特征：损失函数会在一开始的迭代中迅速下降，然后损失函数的变化会异常的平坦（波动范围高度统一），即便再增加训练次数也无法使损失函数下降；模型AUC体现为基本未进行分类。
+ ANN模型如果输入的特征数量较多，而权重矩阵初始化范围为0-1的话，也会出现梯度消失现象。与未标准化的情况本质相同，特征的加权和过高。这种情况可以通过更改权重矩阵的初始化范围至-1到1可缓解。如果特征数量非常多，可相应缩小权重绝对值，如初始化范围设置为-0.001至0.001之间。
+ ANN一般3层神经网络（2个隐层）可模拟任意非线性函数，层数的增加对模型性能影响不大（但据说层数越多反向传播误差越多）。每层神经元的个数设置如果太少的话，可能会导致模型性能不稳定。
### 5.模型线上验证与调整
这一阶段没什么好说的，主要工作是：通过线下AUC与线上AUC对比，判断是否存在过拟合；如果存在过拟合，则需要开展精细化的特征筛选、对抗验证等。

## 五、总结
总结本次竞赛中模型使用和参数设置、特征工程、模型泛用性提升的方法等，主要有以下几点感悟和经验：

### 1.关于过拟合

过拟合一般在教材中会直观的解释为模型学习到了过多细枝末节的特征，导致过度拟合了训练集的数据，在测试集上性能变差，模型泛用性下降。这种解释能够让人迅速直观的理解过拟合的概念，但是对于过拟合的数学本质并没有进行解释，导致初学者从理解过拟合到解决过拟合会走偏。

我认为，机器学习的数学本质是，样本分类或者说预测变量，与样本的特征之间存在着一定的关系，可以类比回归模型和概率分布函数，想象样本取值概率密度与样本特征取值概率密度之间存在一个非线性函数加随机扰动项。当我们说存在过拟合的时候，本质上是在说测试集与训练集中，预测变量取值与特征取值之间的关系存在差异。这个差异可以表现为训练集上存在新的特征，也可以是训练集与测试集上同一特征对变量预测的作用发生变化。机器学习本身是在用各种方法去求解这个未知的分布函数。因此解决过拟合最本质的方法是，在一个足够接近测试集的训练集上面，用机器学习方法求解分布函数，也就是对抗验证。而将过拟合直观的解释为细枝末节特征的过度引入，很容易让初学者在解决过拟合问题时，更多的着眼于低分类效果特征的剔除，而忽视了已有的效果较好的特征也并不值得信赖。有可能这个特征是主干特征，但该特征的作用在测试集发生了变化，从而基于原训练集训练模型不过是缘木求鱼，依旧效果不佳。

### 2.关于如何筛选特征
特征的构造其实很简单，对业务不了解也可以采用数学变换、特征交叉等各种方法进行暴力破解。但暴力破解后的特征如何进行选择需要仔细考虑。最简单直接的特征选择方法，将单个特征输入模型，以AUC分值大小或提升的幅度决胜负，但很明显当样本量比较大、特征数量比较多时，这种方法对时间和算力的要求都比较高；当特征已经经过一轮筛选，需要进一步精细筛选提高模型表现时方可采用。

因为比赛中我们在特征选择时能够高效验证的只有经验误差，泛化误差变化只能通过有限次数的测试集验证得知。因此一个特征是否要纳入模型，一方面要考虑是否能降低经验误差，一方面要考虑是否存在过拟合。所以特征的选择实际上也可以划分为两个阶段：

首先，如何判断特征的加入是否有助于提高模型在训练集的表现（减小经验误差）。这一阶段我对于特征选择的核心原则是：选择分离度较高的特征。分离度是指，特征分布在不同分类上有足够明显的差异，当特征近似服从于正态分布时，分布的差异就体现在均值和标准差上。这一核心原则实际上受到了SVM模型思想的影响。SVM模型的理论前提是不同分类的样本在某个高维特征空间是线性可分的，因此我们可以将特征向量映射为高维向量，实现样本类别的划分。而具体到某一个特征上，线性可分本身意味着样本在该特征上存在较高的分离度。因此我将高分离度的特征挑选出来，这个特征大概率是可以提高模型表现的（尤其是SVM模型）。因此基于这个高分离度的核心原则，我构建了一个简单好用的特征评分指标：在训练集上该样本分类为1的特征取值平均值mean1与分类为0的特征取值平均值mean2之差，除以训练集上该特征的标准差std，即abs(mean1-mean2)/std。因为该评分指标只应用于标准化之后的特征，特征近似服从于标准正态分布，因此特征整体均值为0，标准差为1.倘若不同分类下均值差接近1，即1个标准差，那这个差异实际上已经是非常明显了。具体的评价阈值可以依据需求来确定，我在招商银行比赛中使用的是0.5-0.8为中等分离度特征，0.8-1为高分离度特征，而1以上为超高分离度特征。经过招商比赛的验证，这个方法简单好用，适用于前期特征的快速筛选。如果这个方法失效，一般是特征的预处理和数学变换没做到位。

其次是如何判断高评分特征的加入是否会导致过拟合，即如何在高评分特征中做选择。这一部分的方法本质上是解决过拟合。过拟合意味着测试集和训练集的分布存在差异，而我们特征选择过度迎合了训练集的分布。一个简单直接的思路：我们从训练集中找到特征分布与测试集类似的样本集合，然后基于这个训练集子集进行特征的构造和评分，那么筛选出的特征在测试集上大概率也是适用的。这个思路实际上就是对抗验证的思路。

### 3.关于SVM模型性能提升
SVM模型对样本特征是否进行了标准化有一定要求，但要求不高。如果各个特征的量级都在同一个层面上，不进行严格的标准化也不影响模型性能，比如一个特征进行了标准化，另一个特征经过数学变换后量级由个位数变为十位数百位数，模型性能不会骤降。

SVM模型性能的提高关键是输入增量信息。即加入模型的特征应该提供增量信息，才能够提高样本的高维线性可分程度。提供增量信息比较难以衡量，但其必要条件是新输入的特征必定是高分离度的特征。因此前期SVM模型性能的提升可以靠特征评分+高评分特征输入模型实现，后期特征足够多后就需要逐特征精细化的评估。例如在B榜期间，我发现同样是高分离度的特征，其中一个特征加入模型反而会降低模型AUC。总之高分离度特征是增量信息的必要条件，但不是充分条件。

### 4.关于如何达到ANN模型性能下限
ANN模型对特征标准化/归一化的要求非常高。如果使用sigmoid函数作为激活函数的话，不对高量级的特征进行标准化会导致模型出现梯度消失现象，最终模型性能低下。比较典型的特征：损失函数会在一开始的迭代中迅速下降，然后损失函数的变化会异常的平坦（波动范围高度统一），即便再增加训练次数也无法使损失函数下降；模型AUC体现为基本未进行分类。

ANN模型如果输入的特征数量较多，而权重矩阵初始化范围为0-1的话，也会出现梯度消失现象。与未标准化的情况本质相同，特征的加权和过高。这种情况可以通过更改权重矩阵的初始化范围至-1到1可缓解。如果特征数量非常多，可相应缩小权重绝对值，如初始化范围设置为-0.001至0.001之间。


