# 招商银行Fintech数据竞赛总结（精简版）
总结本次竞赛中模型使用和参数设置、特征工程、模型泛用性提升的方法等，主要有以下几点感悟和经验：

## 1.关于过拟合

过拟合一般在教材中会直观的解释为模型学习到了过多细枝末节的特征，导致过度拟合了训练集的数据，在测试集上性能变差，模型泛用性下降。**这种解释能够让人迅速直观的理解过拟合的概念，但是对于过拟合的数学本质并没有进行解释**，导致初学者从理解过拟合到解决过拟合会走偏。

**我认为，机器学习的数学本质是，样本分类或者说预测变量，与样本的特征之间存在着一定的关系，可以类比回归模型和概率分布函数，想象样本取值概率密度与样本特征取值概率密度之间存在一个非线性函数加随机扰动项。** 当我们说存在过拟合的时候，本质上是在说测试集与训练集中，预测变量取值与特征取值之间的关系存在差异。**这个差异可以表现为训练集上存在新的特征，也可以是训练集与测试集上同一特征对变量预测的作用发生变化**。机器学习本身是在用各种方法去求解这个未知的分布函数。因此解决过拟合最本质的方法是，在一个足够接近测试集的训练集上面，用机器学习方法求解分布函数，也就是对抗验证。而**将过拟合直观的解释为细枝末节特征的过度引入，很容易让初学者在解决过拟合问题时，更多的着眼于低分类效果特征的剔除，而忽视了已有的效果较好的特征也并不值得信赖**。有可能这个特征是主干特征，但该特征的作用在测试集发生了变化，从而基于原训练集训练模型不过是缘木求鱼，依旧效果不佳。

## 2.关于如何筛选特征
特征的构造其实很简单，对业务不了解也可以采用数学变换、特征交叉等各种方法进行暴力破解。但暴力破解后的特征如何进行选择需要仔细考虑。最简单直接的特征选择方法，将单个特征输入模型，以AUC分值大小或提升的幅度决胜负，但很明显当样本量比较大、特征数量比较多时，这种方法对时间和算力的要求都比较高；当特征已经经过一轮筛选，需要进一步精细筛选提高模型表现时方可采用。

因为比赛中我们在特征选择时能够高效验证的只有经验误差，泛化误差变化只能通过有限次数的测试集验证得知。因此一个特征是否要纳入模型，一方面要考虑是否能降低经验误差，一方面要考虑是否存在过拟合。所以**特征的选择实际上也可以划分为两个阶段**：

**首先，如何判断特征的加入是否有助于提高模型在训练集的表现（减小经验误差）。这一阶段我对于特征选择的核心原则是：选择分离度较高的特征**。分离度是指，特征分布在不同分类上有足够明显的差异，当特征近似服从于正态分布时，分布的差异就体现在均值和标准差上。这一核心原则实际上受到了SVM模型思想的影响。SVM模型的理论前提是不同分类的样本在某个高维特征空间是线性可分的，因此我们可以将特征向量映射为高维向量，实现样本类别的划分。而具体到某一个特征上，线性可分本身意味着样本在该特征上存在较高的分离度。因此我将高分离度的特征挑选出来，这个特征大概率是可以提高模型表现的（尤其是SVM模型）。因此**基于这个高分离度的核心原则，我构建了一个简单好用的特征评分指标：在训练集上该样本分类为1的特征取值平均值mean1与分类为0的特征取值平均值mean2之差，除以训练集上该特征的标准差std，即abs(mean1-mean2)/std**。因为该评分指标只应用于标准化之后的特征，特征近似服从于标准正态分布，因此特征整体均值为0，标准差为1.倘若不同分类下均值差接近1，即1个标准差，那这个差异实际上已经是非常明显了。具体的评价阈值可以依据需求来确定，我在招商银行比赛中使用的是0.5-0.8为中等分离度特征，0.8-1为高分离度特征，而1以上为超高分离度特征。**经过招商比赛的验证，这个方法简单好用，适用于前期特征的快速筛选**。如果这个方法失效，一般是特征的预处理和数学变换没做到位。

**其次是如何判断高评分特征的加入是否会导致过拟合，即如何在高评分特征中做选择**。这一部分的方法本质上是解决过拟合。过拟合意味着测试集和训练集的分布存在差异，而我们特征选择过度迎合了训练集的分布。一个简单直接的思路：我们从训练集中找到特征分布与测试集类似的样本集合，然后基于这个训练集子集进行特征的构造和评分，那么筛选出的特征在测试集上大概率也是适用的。这个思路实际上就是对抗验证的思路。

## 3.关于SVM模型性能提升
SVM模型对样本特征是否进行了标准化有一定要求，但要求不高。如果各个特征的量级都在同一个层面上，不进行严格的标准化也不影响模型性能，比如一个特征进行了标准化，另一个特征经过数学变换后量级由个位数变为十位数百位数，模型性能不会骤降。

**SVM模型性能的提高关键是输入增量信息。即加入模型的特征应该提供增量信息，才能够提高样本的高维线性可分程度**。提供增量信息比较难以衡量，但其必要条件是新输入的特征必定是高分离度的特征。因此前期SVM模型性能的提升可以靠特征评分+高评分特征输入模型实现，后期特征足够多后就需要逐特征精细化的评估。例如在B榜期间，我发现同样是高分离度的特征，其中一个特征加入模型反而会降低模型AUC。总之**高分离度特征是增量信息的必要条件，但不是充分条件**。

## 4.关于如何达到ANN模型性能下限
ANN模型对特征标准化/归一化的要求非常高。**如果使用sigmoid函数作为激活函数的话，不对高量级的特征进行标准化会导致模型出现梯度消失现象，最终模型性能低下**。比较典型的特征：损失函数会在一开始的迭代中迅速下降，然后损失函数的变化会异常的平坦（波动范围高度统一），即便再增加训练次数也无法使损失函数下降；模型AUC体现为基本未进行分类。

**ANN模型如果输入的特征数量较多，而权重矩阵初始化范围为0-1的话，也会出现梯度消失现象**。与未标准化的情况本质相同，特征的加权和过高。这种情况可以通过更改权重矩阵的初始化范围至-1到1可缓解。如果特征数量非常多，可相应缩小权重绝对值，如初始化范围设置为-0.001至0.001之间。
